# Importa√ß√µes necess√°rias
import urllib.parse
import re
from bs4 import BeautifulSoup
from playwright.sync_api import sync_playwright

# URL do site da FIESC
FIESC_URL = "https://portaldecompras.fiesc.com.br/Portal/Mural.aspx"
BASE_URL = "https://portaldecompras.fiesc.com.br"

# ==============================================================================
# 1. FUN√á√ïES ESSENCIAIS (Copiadas do seu script principal)
# ==============================================================================

def fetch_dynamic(url, wait_selector="table, div"):
    """Busca o HTML usando o Playwright para conte√∫do din√¢mico."""
    with sync_playwright() as p:
        # Nota: headless=True significa que o navegador n√£o ser√° vis√≠vel
        browser = p.chromium.launch(headless=True) 
        page = browser.new_page()
        print(f"[FETCH] Acessando: {url}")
        page.goto(url, timeout=60000)
        try:
            # Espera carregar uma tabela ou div que contenha os dados
            page.wait_for_selector(wait_selector, timeout=30000)
        except:
            print("[FETCH] Aviso: O seletor de espera n√£o foi encontrado no tempo limite.")
            pass
        html = page.content()
        browser.close()
        return html
    
def fetch_dynamic_scroll(url, wait_selector="table, div"):
    """
    Busca o HTML usando o Playwright e simula a rolagem da p√°gina 
    para carregar todos os resultados via lazy loading.
    """
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()
        page.goto(url, timeout=60000)
        
        # Espera inicial para o primeiro bloco de conte√∫do
        try:
            page.wait_for_selector(wait_selector, timeout=30000)
        except:
            pass

        print("[FETCH] Iniciando rolagem para carregar todos os itens...")
        
        last_height = -1
        scroll_attempts = 0
        MAX_SCROLL_ATTEMPTS = 50 # Limite de tentativas para evitar loops infinitos

        while scroll_attempts < MAX_SCROLL_ATTEMPTS:
            # 1. Rola at√© o final da p√°gina (executa JS no navegador)
            # O Playwright rola a p√°gina para baixo o m√°ximo poss√≠vel
            page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            
            # 2. Espera o novo conte√∫do ser carregado (ajuste o tempo se necess√°rio)
            # 2 segundos √© um bom tempo para a maioria das requisi√ß√µes AJAX.
            page.wait_for_timeout(2000) 
            
            # 3. Verifica se o tamanho do conte√∫do aumentou
            new_height = page.evaluate("document.body.scrollHeight")
            
            if new_height == last_height:
                # Se o tamanho n√£o mudou, chegamos ao final da lista
                print(f"[FETCH] Fim da lista. Altura estabilizada em {new_height} pixels.")
                break
            
            # 4. Atualiza a altura e continua
            last_height = new_height
            scroll_attempts += 1
            print(f"[FETCH] Rolagem {scroll_attempts} realizada. Nova altura: {new_height}")

        if scroll_attempts == MAX_SCROLL_ATTEMPTS:
            print(f"[FETCH] Aviso: Limite de {MAX_SCROLL_ATTEMPTS} rolagens atingido. Pode haver mais dados.")

        html = page.content()
        browser.close()
        return html

def parse_fiesc_tabela(html, base_url="https://portaldecompras.fiesc.com.br"):
    """
    Parser corrigido para o Mural de Licita√ß√µes da FIESC.
    Extrai o ID da licita√ß√£o do atributo onclick (Coluna 7) para construir o URL absoluto.
    """
    soup = BeautifulSoup(html, "lxml")
    items = []
    
    # Seletor: Busca todas as linhas (tr) dentro do corpo da tabela espec√≠fico
    rows = soup.select("tbody#trListaMuralProcesso tr")
    
    # Regex para extrair o primeiro ID num√©rico dentro da fun√ß√£o de clique
    # Ex: trListaMuralResumoEdital_Click(6577, 59, 6577, true) -> captura '6577'
    ID_PATTERN = re.compile(r"trListaMuralResumoEdital_Click\((\d+),")
    
    # Template do URL de detalhes (formato mais prov√°vel, ajuste se necess√°rio)
    URL_TEMPLATE = base_url + "/Detalhe.aspx?id={}" 
    
    for tr in rows:
        cols = tr.find_all("td")
        
        # Oito colunas esperadas (0 a 7)
        if len(cols) < 8:
            continue
            
        # 1. Extra√ß√£o dos Campos B√°sicos por √çndice
        # Coluna 3: Objeto/Descri√ß√£o (T√≠tulo)
        title = cols[3].get_text(strip=True) 
        # Coluna 2: Unidade Compradora (√ìrg√£o)
        org = cols[2].get_text(strip=True)    
        # Coluna 6: Data/Hora Final (Publicado)
        published_date = cols[6].get_text(strip=True) 
        
        # 2. Extra√ß√£o da URL (Usando onclick da Coluna 7)
        url = None
        
        # O elemento clic√°vel (com onclick) est√° na Coluna 7 (√≠ndice 7)
        area_clique_span = cols[7].select_one("span.areaClique")
        
        if area_clique_span:
            onclick_attr = area_clique_span.get('onclick', '')
            match = ID_PATTERN.search(onclick_attr)
            
            if match:
                process_id = match.group(1) # Captura o ID num√©rico
                url = URL_TEMPLATE.format(process_id) # Constr√≥i o URL absoluto

        # S√≥ adiciona o item se o T√≠tulo E a URL foram encontrados
        if title and url: 
            items.append({
                "title": title, 
                "org": org, 
                "url": url, 
                "published": published_date
            })
        
    return items

# ==============================================================================
# 2. EXECU√á√ÉO DO TESTE
# ==============================================================================

if __name__ == "__main__":
    print("--- üåê Teste Real do Parser FIESC ---")
    
    try:
        # 1. Busca o HTML real e din√¢mico
        html_real = fetch_dynamic_scroll(FIESC_URL)
        
        # 2. Processa o HTML com o parser
        resultados = parse_fiesc_tabela(html_real, BASE_URL)
        
        print(f"\n‚úÖ Total de itens encontrados no site real: {len(resultados)}\n")
        
        # 3. Imprime os resultados
        if resultados:
            for i, item in enumerate(resultados, 1):
                print(f"--- Licita√ß√£o {i} ---")
                print(f"T√≠tulo:    {item['title']}")
                print(f"√ìrg√£o:     {item['org']}")
                print(f"Data:      {item['published']}")
                print(f"URL:       {item['url']}")
                print("-" * 25)
        else:
            print("‚ö†Ô∏è Nenhuma licita√ß√£o foi encontrada. Os seletores HTML podem precisar de ajuste.")

    except Exception as e:
        print(f"\n‚ùå Ocorreu um erro durante o teste: {e}")
        print("Certifique-se de que o Playwright est√° instalado e os drivers est√£o configurados.")
        # Dica para configurar o Playwright:
        # python -m playwright install